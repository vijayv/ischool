{
 "metadata": {
  "name": "",
  "signature": "sha256:cfb7fdb25a9dee3112a1233d2cf92605430145e83856b49e0ba9b1e1a6330b70"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Ensemble"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import glob\n",
      "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier \n",
      "from sklearn import cross_validation, grid_search\n",
      "from math import sqrt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 169
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Prep Prediction Files"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The code below is repeated through out the notebook. I was trying to find a graceful way to easily handle all the different submission files that everyone was sending me because I need to combine them all into master file. The code below essentially just opens each file that each person sends me and adds a column to their submission with their intials + unique index num. I layer pivot on this column so that each prediction will be in its own column."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "team = [\"vv\", \"ar\", \"sj\", \"ns\", \"js\"]\n",
      "# Training\n",
      "for m in team:\n",
      "    path = \"ensemble/training/%s_*.csv\" % m\n",
      "    for i, f in enumerate(glob.glob(path)):\n",
      "        df = pd.read_csv(f, header=0)\n",
      "\n",
      "        if \"member\" in df.columns:\n",
      "            df.drop('member', axis=1, inplace=True)\n",
      "            \n",
      "        df[\"member\"] = m+str(i)\n",
      "        df.to_csv(f, index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 170
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Testing\n",
      "for m in team:\n",
      "    path = \"ensemble/testing/%s_*.csv\" % m\n",
      "    for i, f in enumerate(glob.glob(path)):\n",
      "        df = pd.read_csv(f, header=0)\n",
      "\n",
      "        if \"member\" in df.columns:\n",
      "            df.drop('member', axis=1, inplace=True)\n",
      "            \n",
      "        df[\"member\"] = m+str(i)\n",
      "        df.to_csv(f, index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 171
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Simple Bagging Code"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Take majority vote with equal weight to each submission."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ensemble = pd.DataFrame()\n",
      "for path in glob.glob('ensemble/testing/*.csv'):\n",
      "    df = pd.read_csv(path)\n",
      "    ensemble = ensemble.append(df, ignore_index=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 172
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prediction = ensemble.pivot(\"passenger_id\", \"member\", \"survived\")\n",
      "prediction = prediction.mode(axis=1, numeric_only=True)\n",
      "prediction = prediction[0].reset_index()\n",
      "prediction.columns = [\"passenger_id\", \"survived\"]\n",
      "print prediction.sum()\n",
      "prediction.astype(int).to_csv(\"results/bagging_ensemble_1.csv\", index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "passenger_id    548366\n",
        "survived           198\n",
        "dtype: int64\n"
       ]
      }
     ],
     "prompt_number": 173
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Fancy Ensembling"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Random Forests"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ensemble_X = pd.DataFrame()\n",
      "for path in glob.glob('ensemble/training/*.csv'):\n",
      "    df = pd.read_csv(path)\n",
      "    ensemble_X = ensemble_X.append(df, ignore_index=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 138
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_features = ensemble_X.pivot(\"passenger_id\", \"member\", \"survived\")\n",
      "training_data = pd.read_csv(\"train.csv\")\n",
      "Y = training_data[\"survived\"]\n",
      "X_features.sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 139,
       "text": [
        "member\n",
        "ar0       254\n",
        "js0       244\n",
        "ns0       245\n",
        "sj0       252\n",
        "vv0       256\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 139
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "forest = RandomForestClassifier()\n",
      "tuned_parameters = [{'max_features': ['sqrt', 'log2'], 'n_estimators': [100, 200, 500, 1000]}]\n",
      "rf = grid_search.GridSearchCV(forest, tuned_parameters, cv=5).fit(X_features, Y)\n",
      "\n",
      "test_predictions = rf.predict(X_features)\n",
      "\n",
      "print test_predictions.shape\n",
      "print rf.best_estimator_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(785,)\n",
        "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='sqrt',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=500, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0)\n"
       ]
      }
     ],
     "prompt_number": 140
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Predict on the Testing Set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ensemble_testing_X = pd.DataFrame()\n",
      "for path in glob.glob('ensemble/testing/*.csv'):\n",
      "    df = pd.read_csv(path)\n",
      "    ensemble_testing_X = ensemble_testing_X.append(df, ignore_index=True)\n",
      "\n",
      "X_testing_features = ensemble_testing_X.pivot(\"passenger_id\", \"member\", \"survived\")\n",
      "X_testing_features.sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 142,
       "text": [
        "member\n",
        "ar0       190\n",
        "js0       185\n",
        "ns0       169\n",
        "sj0       209\n",
        "vv0       207\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 142
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Take the same decision trees and run it on the test data\n",
      "test_predictions = rf.predict(X_testing_features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 143
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testing_data = pd.read_csv(\"test.csv\")\n",
      "final_predictions = zip(testing_data[\"passenger_id\"],test_predictions.astype(int))\n",
      "output_columns = \"passenger_id\", \"survived\"\n",
      "final_predictions = pd.DataFrame(final_predictions, columns=output_columns)\n",
      "print final_predictions.sum()\n",
      "print len(final_predictions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "passenger_id    548366\n",
        "survived           175\n",
        "dtype: int64\n",
        "524\n"
       ]
      }
     ],
     "prompt_number": 144
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 144
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "### Remember to change the file name with each iteration of risk losing a good submission!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final_predictions.to_csv(\"results/2_ensemble_random_forest.csv\", index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 145
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Adaboost"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = AdaBoostClassifier(n_estimators=1000)\n",
      "clf = clf.fit(X_features, Y)\n",
      "test_predictions = clf.predict(X_testing_features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 149
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testing_data = pd.read_csv(\"test.csv\")\n",
      "final_predictions = zip(testing_data[\"passenger_id\"],test_predictions.astype(int))\n",
      "output_columns = \"passenger_id\", \"survived\"\n",
      "final_predictions = pd.DataFrame(final_predictions, columns=output_columns)\n",
      "print final_predictions.sum()\n",
      "print len(final_predictions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "passenger_id    548366\n",
        "survived           172\n",
        "dtype: int64\n",
        "524\n"
       ]
      }
     ],
     "prompt_number": 150
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 147
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "### Remember to change the file name with each iteration of risk losing a good submission!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final_predictions.to_csv(\"results/2_ensemble_adaboost.csv\", index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 148
    }
   ],
   "metadata": {}
  }
 ]
}